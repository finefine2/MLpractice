{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit learn import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델링을 위해 분석 및 처리할 데이터 파일 읽기 \n",
    "pandas로 2개 데이터 파일을 읽고 합쳐서 1개의 데이터프레임 df에 할당하는 코드 \n",
    "\n",
    "- A0007IT.json 파일 읽어 데이터프레임 변수 df_a 할당\n",
    "- signal.csv 파일 읽어 데이터프레임 변수 df_b 할당 \n",
    "- df_a와 df_b 데이터프레임을 판다스의 merge 함수를 활용하여 합쳐 데이터프레임 변수 df에 저장 \n",
    "- 합칠때 사용하는 키(on) :'RID'\n",
    "- 합치는 방법(how):'inner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File A0007IT.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_a \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA0007IT.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df_b \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignal.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m      4\u001b[0m pd\u001b[38;5;241m.\u001b[39mmerge(df_a,df_b,on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRID\u001b[39m\u001b[38;5;124m\"\u001b[39m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Yangho_Lee\\udemy\\MLOPS\\machinelearningpipeline\\ml_env\\lib\\site-packages\\pandas\\io\\json\\_json.py:791\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    789\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[1;32md:\\Yangho_Lee\\udemy\\MLOPS\\machinelearningpipeline\\ml_env\\lib\\site-packages\\pandas\\io\\json\\_json.py:904\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[1;32md:\\Yangho_Lee\\udemy\\MLOPS\\machinelearningpipeline\\ml_env\\lib\\site-packages\\pandas\\io\\json\\_json.py:960\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    952\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[0;32m    959\u001b[0m ):\n\u001b[1;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal json to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    967\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    968\u001b[0m     )\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File A0007IT.json does not exist"
     ]
    }
   ],
   "source": [
    "df_a = pd.read_json(\"A0007IT.json\")\n",
    "df_b = pd.read_csv(\"signal.csv\") \n",
    "\n",
    "pd.merge(df_a,df_b,on=\"RID\",how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.font_manager as fm \n",
    "plt.rc('font',family=\"NanumGothicCoding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Address1 에 대한 분포도 알아보기\n",
    "### Address1에 대해 countplot 그래프로 만드는 코드와 답안 작성 \n",
    "- seaborn 활용 \n",
    "- 첫번쨰, Address1에 대해 분포 보여주는 countplot 그래프 그리기 \n",
    "- 두번째, 지역명이 없는 '-'에 해당하는 row 삭제 \n",
    "- 출력된 그래프를 보고 해석한 것으로 옳지 않은 선택지 골라 '답안04'변수 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m \n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m6\u001b[39m)) \n\u001b[0;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mcountplot(data\u001b[38;5;241m=\u001b[39mdf,x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddress1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "plt.figure(figsize=(12,6)) \n",
    "sns.countplot(data=df,x=\"Address1\")\n",
    "plt.xticks(rotation=45) \n",
    "plt.show() \n",
    "df[df[\"Address1\"] != '-']\n",
    "답안04=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.실주행시간과 평균시속의 분표 같이 확인 \n",
    "Time_Driving 과 Speed_Per_Hour jointplot 그래프 만들기 \n",
    "- seaborn 활용 \n",
    "- X 축은 Time_driving y축은 Speed_Per_hour 표기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m6\u001b[39m)) \n\u001b[1;32m----> 2\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mjointplot(data\u001b[38;5;241m=\u001b[39mdf,x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime_Driving\u001b[39m\u001b[38;5;124m\"\u001b[39m,y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeed_Per_Hour\u001b[39m\u001b[38;5;124m\"\u001b[39m,kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreg\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime Driving vs Speed Per Hour\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime_Driving\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6)) \n",
    "sns.jointplot(data=df,x=\"Time_Driving\",y=\"Speed_Per_Hour\",kind=\"reg\") \n",
    "\n",
    "plt.title(\"Time Driving vs Speed Per Hour\") \n",
    "plt.xlabel(\"Time_Driving\") \n",
    "plt.ylabel(\"Speed_Per_Hour\") \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. jointplot 그래프에서 시속 300 이상 이상치 발견 \n",
    "전처리 수행하고 저장할것 \n",
    "- 대상 데이터프레임: df \n",
    "- jointplot 그래프 보고 시속 300 이상 이상치를 찾아 해당 row 삭제 \n",
    "- 불필요한 'RID' 칼럼 삭제 \n",
    "- 전처리 반영 후 새로운 데이터프레임 변수명 df_temp 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_temp \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeed_Per_Hour\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m] \n\u001b[0;32m      2\u001b[0m df_temp \u001b[38;5;241m=\u001b[39m df_temp\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRID\u001b[39m\u001b[38;5;124m\"\u001b[39m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_temp = df[df[\"Speed_Per_Hour\"] < 300] \n",
    "df_temp = df_temp.drop(\"RID\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 결측치 처리 \n",
    "df_temp\n",
    "결측치 확인하는 코드 작성 \n",
    "결측치가 있는 행 삭제 \n",
    "전처리 반영된 결과를 df_na 저장 \n",
    "결측치 개수를 답안07에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m missing_values \u001b[38;5;241m=\u001b[39m \u001b[43mdf_temp\u001b[49m\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      2\u001b[0m 답안07 \u001b[38;5;241m=\u001b[39m df_temp\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39msum() \n\u001b[0;32m      3\u001b[0m df_na \u001b[38;5;241m=\u001b[39m df_temp\u001b[38;5;241m.\u001b[39mdropna()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_temp' is not defined"
     ]
    }
   ],
   "source": [
    "missing_values = df_temp.isnull().sum()\n",
    "답안07 = df_temp.isnull().sum().sum() \n",
    "df_na = df_temp.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 불필요 데이터를 삭제 \n",
    "- df_na \n",
    "- 'Time_Departure','Time_Arrival\" 2개 컬럼 삭제 \n",
    "- 전처리 반영된 결과를 새로운 변수 df_del에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_na' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_del \u001b[38;5;241m=\u001b[39m \u001b[43mdf_na\u001b[49m\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime_Departure\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime_Arrival\u001b[39m\u001b[38;5;124m\"\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_na' is not defined"
     ]
    }
   ],
   "source": [
    "df_del = df_na.drop([\"Time_Departure\",\"Time_Arrival\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. One-hot encoding 으로 아래 조건 데이터를 return \n",
    "- df_del\n",
    "- one_hot encoding 대상: object 타입의 전체 컬럼 \n",
    "- pandas의 get_dummies 활용 \n",
    "- 해당 결과를 df_preset에 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_del' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m object_columns \u001b[38;5;241m=\u001b[39m \u001b[43mdf_del\u001b[49m\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      2\u001b[0m df_preset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df_del,columns\u001b[38;5;241m=\u001b[39mobject_columns) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_del' is not defined"
     ]
    }
   ],
   "source": [
    "object_columns = df_del.select_dtypes(include=[\"object\"]).columns\n",
    "df_preset = pd.get_dummies(df_del,columns=object_columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. train test split\n",
    "\n",
    "Time_Driving 칼럼을 label값 y로, 나머지칼럼을 feature값 x로 할당한 후\n",
    "훈련데이터셋과 검증데이터셋으로 분리하세요\n",
    "\n",
    "추가로 가이드 따라서 훈련데이터셋과 검증데이터셋이 스케일링을 수행하세요\n",
    "\n",
    "대상 데이터프레임: df_preset\n",
    "훈련과 검증데이터셋 분리\n",
    "- 훈련 데이터셋 label: y_train, 훈련 데이터셋 feature: X_train\n",
    "- 검증 데이터셋 label: y_valid, 검증데이터셋 feature: X_valid\n",
    "- 훈련 데이터셋과 검증데이텃 비율은 8:2\n",
    "- random_state: 42\n",
    "- scikit-learn의 train_test_split 함수를 활용할 것\n",
    "\n",
    "RobustScaler 스케일링 수행\n",
    "- sklearn.preprocessing의 RobustScaler함수 사용\n",
    "- 훈련데이터셋의 feature는 RobustScaler의 fit_transform함수를 활용하여 X_train 변수로 할당\n",
    "- 검증데이터셋의 feature는 RobustScaler의 transform 함수를 활용하여 X_test변수로 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_preset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RobustScaler\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 1. feature와 label 분리\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf_preset\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime_Driving\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# feature\u001b[39;00m\n\u001b[0;32m      6\u001b[0m y \u001b[38;5;241m=\u001b[39m df_preset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime_Driving\u001b[39m\u001b[38;5;124m'\u001b[39m]               \u001b[38;5;66;03m# label\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 2. train-test split\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_preset' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# 1. feature와 label 분리\n",
    "X = df_preset.drop('Time_Driving', axis=1)  # feature\n",
    "y = df_preset['Time_Driving']               # label\n",
    "\n",
    "# 2. train-test split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. RobustScaler 객체 생성\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# 4. 스케일링 수행\n",
    "# 훈련데이터: fit_transform 사용\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# 검증데이터: transform 사용\n",
    "X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Time_Driving을 예측하는 ML모델 개발\n",
    "decision tree와 random forest 모델 만들고 학습 진행\n",
    "\n",
    "decision tree\n",
    "- 트리의 최대 깊이: 5\n",
    "- 노드를 분할하기 위한 최소 샘플 데이터수 (min_samples_split): 3\n",
    "- random_state:120\n",
    "- decision tree 모델을 dt변수에 저장\n",
    "\n",
    "RandomForest\n",
    "- 트리 최대 깊이: 5\n",
    "- 노드 분할하기 위한 최소한의 샘플 데이터수 (min_samples_split):3\n",
    "- random_state:120\n",
    "- randomforest 모델을 rf변수에 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Decision Tree 모델 생성 및 학습\u001b[39;00m\n\u001b[0;32m      5\u001b[0m dt \u001b[38;5;241m=\u001b[39m DecisionTreeRegressor(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[0;32m      6\u001b[0m                           min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \n\u001b[0;32m      7\u001b[0m                           random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m dt\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Random Forest 모델 생성 및 학습\u001b[39;00m\n\u001b[0;32m     11\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     12\u001b[0m                           min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     13\u001b[0m                           random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Decision Tree 모델 생성 및 학습\n",
    "dt = DecisionTreeRegressor(max_depth=5, \n",
    "                          min_samples_split=3, \n",
    "                          random_state=120)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest 모델 생성 및 학습\n",
    "rf = RandomForestRegressor(max_depth=5,\n",
    "                          min_samples_split=3,\n",
    "                          random_state=120)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 모델 성능 확인 (선택사항)\n",
    "# Decision Tree\n",
    "dt_train_score = dt.score(X_train, y_train)\n",
    "dt_valid_score = dt.score(X_valid, y_valid)\n",
    "\n",
    "# Random Forest\n",
    "rf_train_score = rf.score(X_train, y_train)\n",
    "rf_valid_score = rf.score(X_valid, y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12모델 성능 평가\n",
    "검증데이터셋 활용(X_valid)\n",
    "방금 만든 decision tree로 y값 예측하여 y_pred_dt 에 저장\n",
    "y_valid와 예측값의 (y_pred_dt) 의 mae를 구하고 dt_mae로 저장\n",
    "\n",
    "randomforest 모델로 y값 예측하여 y_pred_rf 에 저장\n",
    "y_valid와 y_pred_rf간의 mae를 구하고 rf_mae에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Decision Tree 예측 및 MAE 계산\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m y_pred_dt \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_valid\u001b[49m)\n\u001b[0;32m      5\u001b[0m dt_mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_valid, y_pred_dt)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Random Forest 예측 및 MAE 계산\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_valid' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Decision Tree 예측 및 MAE 계산\n",
    "y_pred_dt = dt.predict(X_valid)\n",
    "dt_mae = mean_absolute_error(y_valid, y_pred_dt)\n",
    "\n",
    "# Random Forest 예측 및 MAE 계산\n",
    "y_pred_rf = rf.predict(X_valid)\n",
    "rf_mae = mean_absolute_error(y_valid, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Time_Driving을 예측하는 딥러닝 모델 제작\n",
    "\n",
    "Tensorflow 를 사용\n",
    "hidden layer 2개 이상\n",
    "dropout 0.2비율로 dropout 레이어 1개 추가\n",
    "loss는 MSE\n",
    "하이퍼파라미터 epochs:30, batch_size:16\n",
    "각 epoch마다 loss와 metric 평가하기 위한 데이터로 x_valid, y_valid 사용\n",
    "학습정보는 history에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential, load_model\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, Activation, Dropout, BatchNormalization\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m([\n\u001b[0;32m      2\u001b[0m     Dense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],)),  \u001b[38;5;66;03m# 입력층\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     Dense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),                                   \u001b[38;5;66;03m# 은닉층 1\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     Dropout(\u001b[38;5;241m0.2\u001b[39m),                                                   \u001b[38;5;66;03m# Dropout 층\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     Dense(\u001b[38;5;241m16\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),                                   \u001b[38;5;66;03m# 은닉층 2\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     Dense(\u001b[38;5;241m8\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),                                    \u001b[38;5;66;03m# 은닉층 3\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     Dense(\u001b[38;5;241m1\u001b[39m)                                                        \u001b[38;5;66;03m# 출력층\u001b[39;00m\n\u001b[0;32m      8\u001b[0m ])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 모델 컴파일 - metrics를 'mse'로 변경\u001b[39;00m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # 입력층\n",
    "    Dense(32, activation='relu'),                                   # 은닉층 1\n",
    "    Dropout(0.2),                                                   # Dropout 층\n",
    "    Dense(16, activation='relu'),                                   # 은닉층 2\n",
    "    Dense(8, activation='relu'),                                    # 은닉층 3\n",
    "    Dense(1)                                                        # 출력층\n",
    "])\n",
    "\n",
    "# 모델 컴파일 - metrics를 'mse'로 변경\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "# 모델 요약\n",
    "model.summary()\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. 모델 성능 평가 \n",
    "1개 그래프에 학습 mse와 검증mse 2개 모두 표시\n",
    "2가지 각각의 범례를 'mse', 'val_mse'로 표시\n",
    "타이틀을 'Model MSE'로 표시\n",
    "X축에는 'Epochs', y축에는 'MSE'로 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['mse'], label='mse')\n",
    "plt.plot(history.history['val_mse'], label='val_mse')\n",
    "plt.title('Model MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
